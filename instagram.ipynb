{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4419df0-cc67-4836-aac4-de56c22a28bd",
   "metadata": {},
   "source": [
    "# 인스타그램 로그인\n",
    "<hr>\n",
    "아래에 정의된 함수들을 한 번씩만 실시하고, 이 함수를 사용한 코드들을 모아둔 코드에서 크롤링을 실시하기\n",
    "위의 코드들은 함수를 미리 정의하여, 크롤링 사용에 용이하도록 만든 코드들임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe9a69d-45be-4571-beb8-ffb54c787360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# 크롬 브라우저 열기\n",
    "driver = webdriver.Chrome('C:/Temp/chromedriver')\n",
    "\n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "time.sleep(2)\n",
    "\n",
    "email = '본인 ID'\n",
    "input_id = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[0]\n",
    "input_id.clear()\n",
    "input_id.send_keys(email)\n",
    "\n",
    "password = '본인 PWD' \n",
    "input_pw = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[1]\n",
    "input_pw.clear()\n",
    "input_pw.send_keys(password)\n",
    "input_pw.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a505b65-3a76-484a-9725-132caed22bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스타그램 해시태그 검색\n",
    "\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "import time\n",
    "\n",
    "word = \"산수갑산\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca838c94-31ff-437c-920f-7d69c7dcc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 게시물 개수\n",
    "\n",
    "postnumber = driver.find_elements_by_css_selector(\"span > span.g47SY\")[0].text.replace(',', '')\n",
    "postnumber = int(postnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e600a-9646-4df4-9f60-f0c1e119add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게시물 내용 크롤링\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_content(driver):\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    # 본문 내용 \n",
    "    try:\n",
    "        content = soup.select('div.C4VMK > span')[0].text\n",
    "    except:\n",
    "        content = ' '\n",
    "    # 해시태그 \n",
    "    try:\n",
    "        tags = re.findall(r'#[^\\s#,\\\\]+', content)  \n",
    "    except:\n",
    "        tags = ' '\n",
    "    # 작성일자 \n",
    "    try:\n",
    "        date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "    except:\n",
    "        date = ''\n",
    "    # 좋아요 \n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1]   \n",
    "    except:\n",
    "        like = 0\n",
    "    # 위치\n",
    "    try: \n",
    "        place = soup.select('div.M30cS')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "   \n",
    "    data = [content, date, like, place, tags]\n",
    "    time.sleep(1)\n",
    "    return data\n",
    "    \n",
    "\n",
    "get_content(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e8d7a-794c-4707-a8d3-97ea31e1b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 게시물로 이동\n",
    "\n",
    "def move_next(driver):\n",
    "\n",
    "    right = driver.find_element_by_css_selector ('a.coreSpriteRightPaginationArrow')\n",
    "    right.click()\n",
    "\n",
    "move_next(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da4481-d4a0-4636-848f-2895c64a4a27",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 인스타그램 게시물 크롤링 하기    <img src='data/instagram.PNG' width=120 height=120 align=\"right\">         \n",
    "### : 본격적인 크롤링은 아래의 코드를 사용하기\n",
    "<hr>\n",
    "위에 코드들을 한 번 씩 실행 후, 아래의 코드에 word 내용만 변경하여 실행하면 반복 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef74a60-9fd7-4e80-bb66-74f00a41d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('output/음식점 모음.xlsx').fillna(\"missing\")\n",
    "\n",
    "for i in range(30) :\n",
    "    for j in range(20) :\n",
    "        if df.iloc[i, j] != \"missing\":\n",
    "            search = df.iloc[i, j].replace(' ', '')\n",
    "\n",
    "            url = insta_searching(search)\n",
    "            driver.get(url)\n",
    "            time.sleep(8)\n",
    "\n",
    "            postnumber = driver.find_elements_by_css_selector(\"span > span.g47SY\")[0].text.replace(',', '')\n",
    "            postnumber = int(postnumber)\n",
    "\n",
    "            select_first(driver)\n",
    "            instagram = []\n",
    "            data = []\n",
    "\n",
    "            for k in range(200) :\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "                # 본문 내용 \n",
    "                try:\n",
    "                    content = soup.select('div.C4VMK > span')[0].text\n",
    "                except:\n",
    "                    content = ' '\n",
    "                # 해시태그 \n",
    "                try:\n",
    "                    tags = re.findall(r'#[^\\s#,\\\\]+', content)  \n",
    "                except:\n",
    "                    tags = ' '\n",
    "                # 작성일자 \n",
    "                try:\n",
    "                    date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "                except:\n",
    "                    date = ''\n",
    "                # 좋아요 \n",
    "                try:\n",
    "                    like = soup.select('div.Nm9Fw > button')[0].text[4:-1]   \n",
    "                except:\n",
    "                    like = 0\n",
    "                # 위치\n",
    "                try: \n",
    "                    place = soup.select('div.M30cS')[0].text\n",
    "                except:\n",
    "                    place = ''\n",
    "\n",
    "                data = [content, date, like, place, tags]\n",
    "                instagram = (instagram,data,'\\n')\n",
    "                time.sleep(0.5)\n",
    "                move_next(driver)\n",
    "                time.sleep(2)\n",
    "           \n",
    "            data_df = pd.DataFrame(instagram)\n",
    "            data_df.columns = ['content','hashtag','date','like','place']\n",
    "            data_df.to_excel('./data/instagram/'+ search +'.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218089e-28e6-4888-ab9c-3e4e099de9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
