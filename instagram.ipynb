{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4419df0-cc67-4836-aac4-de56c22a28bd",
   "metadata": {},
   "source": [
    "# 인스타그램 로그인\n",
    "<hr>\n",
    "아래에 정의된 함수들을 한 번씩만 실시하고, 이 함수를 사용한 코드들을 모아둔 코드에서 크롤링을 실시하기\n",
    "위의 코드들은 함수를 미리 정의하여, 크롤링 사용에 용이하도록 만든 코드들임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9a69d-45be-4571-beb8-ffb54c787360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# 크롬 브라우저 열기\n",
    "driver = webdriver.Chrome('C:/Temp/chromedriver')\n",
    "\n",
    "driver.get(\"https://www.instagram.com/accounts/login/\")\n",
    "time.sleep(2)\n",
    "\n",
    "email = '본인 ID'\n",
    "input_id = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[0]\n",
    "input_id.clear()\n",
    "input_id.send_keys(email)\n",
    "\n",
    "password = '본인 PWD' \n",
    "input_pw = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[1]\n",
    "input_pw.clear()\n",
    "input_pw.send_keys(password)\n",
    "input_pw.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a505b65-3a76-484a-9725-132caed22bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스타그램 해시태그 검색\n",
    "\n",
    "def insta_searching(word):\n",
    "    url = \"https://www.instagram.com/explore/tags/\" + word\n",
    "    return url\n",
    "import time\n",
    "\n",
    "word = \"산수갑산\"\n",
    "url = insta_searching(word)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca838c94-31ff-437c-920f-7d69c7dcc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 게시물 개수\n",
    "\n",
    "postnumber = driver.find_elements_by_css_selector(\"span > span.g47SY\")[0].text.replace(',', '')\n",
    "postnumber = int(postnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a75be7-e862-4611-b4c7-d88bab5018e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 게시물 열기\n",
    "\n",
    "def select_first(driver):\n",
    "    first = driver.find_element_by_css_selector(\"div._9AhH0\")\n",
    "    first.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "select_first(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e600a-9646-4df4-9f60-f0c1e119add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게시물 내용 크롤링\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_content(driver):\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    # 본문 내용 \n",
    "    try:\n",
    "        content = soup.select('div.C4VMK > span')[0].text\n",
    "    except:\n",
    "        content = ' '\n",
    "    # 해시태그 \n",
    "    try:\n",
    "        tags = re.findall(r'#[^\\s#,\\\\]+', content)  \n",
    "    except:\n",
    "        tags = ' '\n",
    "    # 작성일자 \n",
    "    try:\n",
    "        date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "    except:\n",
    "        date = ''\n",
    "    # 좋아요 \n",
    "    try:\n",
    "        like = soup.select('div.Nm9Fw > button')[0].text[4:-1]   \n",
    "    except:\n",
    "        like = 0\n",
    "    # 위치\n",
    "    try: \n",
    "        place = soup.select('div.M30cS')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "   \n",
    "    data = [content, date, like, place, tags]\n",
    "    time.sleep(1)\n",
    "    return data\n",
    "    \n",
    "\n",
    "get_content(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e8d7a-794c-4707-a8d3-97ea31e1b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 게시물로 이동\n",
    "\n",
    "def move_next(driver):\n",
    "\n",
    "    right = driver.find_element_by_css_selector ('a.coreSpriteRightPaginationArrow')\n",
    "    right.click()\n",
    "\n",
    "move_next(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da4481-d4a0-4636-848f-2895c64a4a27",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 인스타그램 게시물 크롤링 하기    <img src='data/instagram.PNG' width=120 height=120 align=\"right\">         \n",
    "### : 본격적인 크롤링은 아래의 코드를 사용하기\n",
    "<hr>\n",
    "위에 코드들을 한 번 씩 실행 후, 아래의 코드에 word 내용만 변경하여 실행하면 반복 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef74a60-9fd7-4e80-bb66-74f00a41d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('output/음식점 모음.xlsx').fillna(\"missing\")\n",
    "\n",
    "for i in range(30) :\n",
    "    for j in range(20) :\n",
    "        if df.iloc[i, j] != \"missing\":\n",
    "            search = df.iloc[i, j].replace(' ', '')\n",
    "\n",
    "            url = insta_searching(search)\n",
    "            driver.get(url)\n",
    "            time.sleep(8)\n",
    "\n",
    "            postnumber = driver.find_elements_by_css_selector(\"span > span.g47SY\")[0].text.replace(',', '')\n",
    "            postnumber = int(postnumber)\n",
    "\n",
    "            select_first(driver)\n",
    "            instagram = []\n",
    "            data = []\n",
    "\n",
    "            for k in range(101) :\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "                # 본문 내용 \n",
    "                try:\n",
    "                    content = soup.select('div.C4VMK > span')[0].text\n",
    "                except:\n",
    "                    content = ' '\n",
    "                # 해시태그 \n",
    "                try:\n",
    "                    tags = re.findall(r'#[^\\s#,\\\\]+', content)  \n",
    "                except:\n",
    "                    tags = ' '\n",
    "                # 작성일자 \n",
    "                try:\n",
    "                    date = soup.select('time._1o9PC.Nzb55')[0]['datetime'][:10]\n",
    "                except:\n",
    "                    date = ''\n",
    "                # 좋아요 \n",
    "                try:\n",
    "                    like = soup.select('div.Nm9Fw > button')[0].text[4:-1]   \n",
    "                except:\n",
    "                    like = 0\n",
    "                # 위치\n",
    "                try: \n",
    "                    place = soup.select('div.M30cS')[0].text\n",
    "                except:\n",
    "                    place = ''\n",
    "\n",
    "                data = [content, date, like, place, tags]\n",
    "                instagram = (instagram,data,'\\n')\n",
    "                time.sleep(0.5)\n",
    "                move_next(driver)\n",
    "                time.sleep(2)\n",
    "           \n",
    "            data_df = pd.DataFrame(instagram)\n",
    "            data_df.columns = ['content','hashtag','date','like','place']\n",
    "            data_df.to_excel('./data/instagram/'+ search +'.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78c0a6-6566-4555-86f5-ac576d9fbb66",
   "metadata": {},
   "source": [
    "# 이어지는 분석\n",
    "<hr>\n",
    "\n",
    "## 파급력 분석하기\n",
    "power = power3 = (기준일 후 게시물 개수 / [(가장 마지막 게시물 날짜- 기준일) / (마지막날짜 - 오래된 날짜) * 100] - 기준일 전 게시물 개수 / [(기준일 - 게시물 중 가장 오래된 날짜) / (마지막날짜 - 오래된 날짜) * 100]\n",
    "reliability2 = reference_after/(reference_affter - resource_count) * 100%\n",
    "\n",
    "## 신뢰도 분석하기\n",
    "reliability1 = resource_count / reference_after * 100% \n",
    "\n",
    "<hr>\n",
    "<br>\n",
    "* resource_count값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(0 , 200))\n",
    "* file : power3(사람별 - 해당 미디어의 영향력) power3값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?)) \n",
    "* (사람별 - 영향력의 크기) reliability2값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?)) \n",
    "* (사람별 - 글을 작성할 확률) reliability값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?)) \n",
    "* ~~글씨체 정하기~~\n",
    "* 산점도 그리기 : (resource - power3) (20 - (-? - ?))\n",
    "* 히트맵 : 블로그 게시물 개수(200개 아님)\n",
    "* 시계열 / 워드 클라우드(자주 사용하는 단어 찾기) 47- 하니칼국수 - 성시경 / 181-코카모메-츄릅켠 / 270-전참시-몽탄\n",
    "* 분산분석(미디어별 - 해당 미디어의 영향력) power3값\n",
    "* 분산분석(미디어별 - 영향력의 크기) reliability2값\n",
    "* 분산분석(미디어별 - 글을 작성할 확률) reliability값\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4032b06-69c3-4efc-9e61-f393cfd3d1ea",
   "metadata": {},
   "source": [
    "## 논점\n",
    "- 2차 생산물을 알지 못함\n",
    "- 모집단을 조사한 것이 아니라 일부 표본을 조사한 것\n",
    "- 작성자의 해시태그와 게시글을 통해 작성자의 취향을 파악하여, 마케팅에 사용할 수 있을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f814a-3af6-442b-8dae-1943057c0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 한 데 모으기\n",
    "import os\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt  # kkma 사용하면, 개수가 안 맞음 \n",
    "\n",
    "okt = Okt()     \n",
    "\n",
    "total = pd.DataFrame()\n",
    "temp = pd.DataFrame()\n",
    "count_theName = pd.DataFrame()\n",
    "\n",
    "path_dir = './data/instagram/rowdata'\n",
    "file_list = os.listdir(path_dir)\n",
    "\n",
    "# 데이터들이 들어있는 파일 열기\n",
    "for l in file_list :\n",
    "    tflist = pd.DataFrame()\n",
    "    splited_dir = l.split('_')\n",
    "    file = \"./data/instagram/rowdata/\" + l \n",
    "    temp_items = pd.read_csv(file, engine='python') # engine을 주지 않으면, encoding에러가 남\n",
    "\n",
    "    for k in range(len(temp_items.index)) : \n",
    "        if splited_dir[1].replace(\".csv\", \"\") in (okt.nouns(temp_items.loc[k, \"content\"].replace(\"#\",\"\") + temp_items.loc[k, \"hashtag\"].replace(\"#\",\"\"))) :\n",
    "            tf = pd.DataFrame(temp_items.loc[k]).transpose()\n",
    "            tflist = tflist.append(tf, ignore_index=True)\n",
    "            if tflist is not None :\n",
    "                date = tflist.sort_values(by='date', ascending=True).head(1)\n",
    "                theDay = str(date.iloc[0, 3])                \n",
    "            else :\n",
    "                theDay = \"2099-12-31\"\n",
    "        oldestdate = temp_items.sort_values(by='date', ascending=True).head(1)\n",
    "        oldestDate = str(oldestdate.iloc[0, 3])\n",
    "        updateddate = temp_items.sort_values(by='date', ascending=False).head(1)\n",
    "        updatedDate = str(updateddate.iloc[0, 3])\n",
    "\n",
    "    tflist.to_csv('./data/instagram/referenceONLY/'+ splited_dir[0] + '_' + splited_dir[1], encoding=\"utf-8\")    \n",
    "\n",
    "    mediaName = splited_dir[1].replace(\".csv\", \"\")\n",
    "    restaurant = splited_dir[0]\n",
    "    data = pd.DataFrame([mediaName, restaurant, oldestDate, theDay, updatedDate]).transpose()         \n",
    "    total = total.append(data, ignore_index = True)\n",
    "    temp = temp.append(temp_items, ignore_index = True) \n",
    "                         \n",
    "temp.to_csv('./data/instagram/sumData.csv', encoding=\"utf-8\")\n",
    "total.to_csv('./data/instagram/instagramtotal.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ff574-4b32-49ec-9a68-b596113da596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "df = pd.read_csv('./data/instagram/instagramtotal.csv')\n",
    "df = df.drop([df.columns[0]], axis = 1)\n",
    "df.columns = ['mediaName', 'restaurant', 'oldestDate', 'theDay', 'updatedDate']\n",
    "display(df)\n",
    "\n",
    "df.theDay = pd.to_datetime(df[\"theDay\"])\n",
    "df.oldestDate = pd.to_datetime(df[\"oldestDate\"])\n",
    "df.updatedDate = pd.to_datetime(df[\"updatedDate\"])\n",
    "df['before_theDay'] = (df.theDay - df.oldestDate).dt.days\n",
    "df['after_theDay'] = (df.updatedDate - df.theDay).dt.days\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16414b-197b-4b07-bc70-044edc70aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_dir = './data/instagram/referenceONLY'\n",
    "file_list = os.listdir(path_dir)\n",
    "\n",
    "countName = []\n",
    "for l in file_list :    \n",
    "    splited_dir = l.split('_')\n",
    "    file = \"./data/instagram/referenceONLY/\" + l \n",
    "    try :\n",
    "        temp_items = pd.read_csv(file, engine='python')\n",
    "        count = len(temp_items)\n",
    "        countName.append(count)\n",
    "    except :\n",
    "        countName.append(0)\n",
    "df[\"countName\"] = countName\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e50059-e0ec-4fe0-86c1-09e2e6494262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt  # kkma 사용하면, 개수가 안 맞음 \n",
    "\n",
    "okt = Okt()     \n",
    "reference_before = []\n",
    "reference_after = []\n",
    "total = pd.DataFrame()\n",
    "temp = pd.DataFrame()\n",
    "count_theName = pd.DataFrame()\n",
    "\n",
    "path_dir = './data/instagram/rowdata'\n",
    "file_list = os.listdir(path_dir)\n",
    "\n",
    "# 데이터들이 들어있는 파일 열기\n",
    "for l in file_list :\n",
    "    tflist = pd.DataFrame()\n",
    "    splited_dir = l.split('_')\n",
    "    file = \"./data/instagram/rowdata/\" + l \n",
    "    temp_items = pd.read_csv(file, engine='python') # engine을 주지 않으면, encoding에러가 남\n",
    "\n",
    "    for k in range(len(temp_items.index)) : \n",
    "        if splited_dir[1].replace(\".csv\", \"\") in (okt.nouns(temp_items.loc[k, \"content\"].replace(\"#\",\"\") + temp_items.loc[k, \"hashtag\"].replace(\"#\",\"\"))) :\n",
    "            tf = pd.DataFrame(temp_items.loc[k]).transpose()\n",
    "            tflist = tflist.append(tf, ignore_index=True)\n",
    "            date = tflist.sort_values(by='date', ascending=True).head(1)\n",
    "            theDay = str(date.iloc[0, 3])                \n",
    "    before = len(temp_items.loc[temp_items['date'] < theDay])\n",
    "    reference_before.append(before)\n",
    "    after = len(temp_items.loc[temp_items['date'] >= theDay])\n",
    "    reference_after.append(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce316308-ba38-4f0a-be7c-61e5c758aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reference_before\"] = reference_before\n",
    "df[\"reference_after\"] = reference_after\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53616bb1-0178-4e14-872e-7b0baa2efdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power열 추가\n",
    "# (기준일 후 게시물 개수 / [(가장 마지막 게시물 날짜- 기준일) / (마지막날짜 - 오래된 날짜) * 100] - 기준일 전 게시물 개수 / [(기준일 - 게시물 중 가장 오래된 날짜) / (마지막날짜 - 오래된 날짜) * 100]\n",
    "# [기준일 후 게시물 개수 / (가장 마지막 게시물 날짜- 기준일) - 기준일 전 게시물 개수 / (기준일 - 게시물 중 가장 오래된 날짜)]* 100 *(마지막날짜 - 오래된 날짜)\n",
    "df[\"power\"] = (df[\"reference_after\"] / df.after_theDay - df[\"reference_before\"] / df.before_theDay) * pd.to_numeric((df[\"updatedDate\"] - df[\"oldestDate\"]).dt.days, downcast='integer') / 100\n",
    "\n",
    "# reliability = resource_count / reference_after * 100%  \n",
    "# reliability2 = reference_after/(reference_affter - resource_count) *100%  \n",
    "# reliability2열 추가\n",
    "df[\"reliability2\"] = df[\"reference_after\"] / (df[\"reference_after\"] - df[\"countName\"]) * 100\n",
    "# reliability열 추가\n",
    "df[\"reliability\"] = df[\"countName\"] / df[\"reference_after\"] * 100\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8d594-a112-42fd-b892-7dd9e850c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/instagram/instagramtotal.csv\")\n",
    "df = df.sort_values(by='mediaName', ascending=True)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e9152-0edf-442f-8554-19dcc4121863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹열 만들기\n",
    "연예인 = [\"이영자\", \"백종원\", \"성시경\", \"신동엽\", \"최자\", \"정지훈\", \"문세윤\", \"김준현\"]\n",
    "유튜버 = [\"더들리\", \"츄릅켠\"]\n",
    "방송프로그램 = [\"수요미식회\", \"생생정보통\", \"전참시\", \"생활의달인\", \"6시내고향\", \"골목식당\", \"생방송오늘저녁\", \"모닝와이드\", \"맛있는녀석들\", \"생방송투데이\"]\n",
    "groups = [연예인, 유튜버, 방송프로그램]\n",
    "groups_names = [\"연예인\", \"유튜버\", \"방송프로그램\"]\n",
    "for i, groups in enumerate(groups):\n",
    "    for media in groups:\n",
    "        df.loc[df[\"mediaName\"] == media, \"group\"] = groups_names[i]\n",
    "display(df)\n",
    "df.to_csv(\"./data/instagram/instagramtotal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fec7db-1c69-4fe8-8833-053cab796f71",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 시각화 하기\n",
    "\n",
    "## 산점도 그리기 : (resource - power3) (20 - (-? - ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55662ca-b9ca-403a-b756-02806b354827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 폰트설정\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"../PYDATAexam/data/malgun.ttf\"   #폰트파일의 위치\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name() # rc 함수를 통해, rcParams에 사용되는 폰트의 정식명칭을 알 수 있음\n",
    "print(font_name)\n",
    "rc('font', family=font_name)\n",
    "\n",
    "data = pd.read_csv(\"./data/instagram/instagramtotal.csv\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751510d1-d241-4edb-96a6-e99b74f2a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타일 테마 설정 (5가지: darkgrid, whitegrid, dark, white, ticks)\n",
    "# sns.set_style('white')\n",
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "#이산형 변수의 분포 - 데이터 분산 고려 (중복 X) \n",
    "sns.swarmplot(x=\"mediaName\",      #x축 변수\n",
    "              y=\"power\",        #y축 변수\n",
    "              data=data)   #데이터셋 - 데이터프레임\n",
    "\n",
    "# data.plot(kind='scatter', x='resource', y='power3', marker='+',\n",
    "#         cmap='viridis', s=50, alpha=0.3, figsize=(20, 5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4767d7-b045-49e6-a532-e12be80b917c",
   "metadata": {},
   "source": [
    "## 막대 그래프 그리기\n",
    "* file : power3(사람별 - 해당 미디어의 영향력) power3값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?))\n",
    "* (사람별 - 영향력의 크기) reliability2값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?))\n",
    "* (사람별 - 글을 작성할 확률) reliability값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9245ed-12c3-4ef4-95f9-89b373bbf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby(\"mediaName\").mean(\"countName\")\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e67c9-b807-4a09-997a-2fc54b5fbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"사람별 식당 언급 횟수의 평균\")\n",
    "r = df1.power.plot(kind='bar')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae335b20-bfbc-43eb-b18e-7ad909acdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "\n",
    "\n",
    "x = df1.index\n",
    "y = df1.countName\n",
    "\n",
    "plt.title(\"사람별 파급력(power)과 신뢰도(reliability)의 평균\")\n",
    "plt.bar(x, y)\n",
    "\n",
    "for i, v in enumerate(x):\n",
    "    plt.text(v, y[i], round(df1.reliability[i], 2),       \n",
    "             fontsize = 9, \n",
    "             color='black',\n",
    "             horizontalalignment='center',  \n",
    "             verticalalignment='bottom')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65340d-1ffb-4b0e-b328-a133945f7688",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 분산분석을 통하여 3개 이상의 집단 간에 차이가 존재하는지 분석하고자 함\n",
    "\n",
    "<p>가설1 : 미디어에 따라 파급력의 차이가 있는가?</p>\n",
    "<p>가설2 : 미디어에 따라 파급력을 미치는 크기에 차이가 있는가?</p>\n",
    "<p>가설3 : 미디어에 따라 글을 작성할 확률에 차이가 있는가?</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>분산분석(미디어별 - 해당 미디어의 영향력) power값</p>\n",
    "<p>분산분석(미디어별 - 영향력의 크기) reliability2값</p>\n",
    "<p>분산분석(미디어별 - 글을 작성할 확률) reliability값</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f9dd0-e3cd-4ed5-8e0f-eac9ebab600f",
   "metadata": {},
   "source": [
    "## 가설1 : 미디어에 따라 파급력의 차이가 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927c205-2411-4dc9-98c6-10227fcef8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "model = ols(\"df['power'] ~ df['group']\", df).fit()\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d6e23-91cb-4a31-a73a-676a85ff90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집단 간의 차이가 유의할 경우, 어느 집단 간에 차이가 나타나는지 보다 구체적으로 보기 위하여 '사후 분석'을 실시\n",
    "# 여기서는 봉페르니 방식의 교정과 Tukey HSD의 방법으로 사후분석\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "import scipy.stats\n",
    "\n",
    "comp = MultiComparison(df['power'], df['group'])\n",
    "result = comp.allpairtest(scipy.stats.ttest_ind, method='bonf') # 봉페르니\n",
    "print(result[0])\n",
    "\n",
    "#투키의 HSD - Tuckey's Honestly Significant Difference = \"진정으로 유의미한 차이\"\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "hsd = pairwise_tukeyhsd(df['power'], df['group'], alpha=0.05)\n",
    "hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c7fb9-aca0-4900-ac50-e0b228466973",
   "metadata": {},
   "source": [
    "## 가설2 : 미디어에 따라 파급력을 미치는 크기에 차이가 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b852185-79af-4a8a-ba1a-90dbb9a63ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"df['reliability'] ~ df['group']\", df).fit()\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c448c7e-fd09-4a41-b4e2-291be65483c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집단 간의 차이가 유의할 경우, 어느 집단 간에 차이가 나타나는지 보다 구체적으로 보기 위하여 '사후 분석'을 실시\n",
    "# 여기서는 봉페르니 방식의 교정과 Tukey HSD의 방법으로 사후분석\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "import scipy.stats\n",
    "\n",
    "comp = MultiComparison(df['reliability'], df['group'])\n",
    "result = comp.allpairtest(scipy.stats.ttest_ind, method='bonf') # 봉페르니\n",
    "print(result[0])\n",
    "\n",
    "#투키의 HSD - Tuckey's Honestly Significant Difference = \"진정으로 유의미한 차이\"\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "hsd = pairwise_tukeyhsd(df['reliability'], df['group'], alpha=0.05)\n",
    "hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23619de2-0afb-4e28-80e4-fff42a872e76",
   "metadata": {},
   "source": [
    "## 가설3 : 미디어에 따라 글을 작성할 확률에 차이가 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746bfdd-3ac4-4712-8a86-26014f34f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"df['reliability2'] ~ df['group']\", df).fit()\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c4a66-0da7-4218-a6fb-9958bbc47510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집단 간의 차이가 유의할 경우, 어느 집단 간에 차이가 나타나는지 보다 구체적으로 보기 위하여 '사후 분석'을 실시\n",
    "# 여기서는 봉페르니 방식의 교정과 Tukey HSD의 방법으로 사후분석\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "import scipy.stats\n",
    "\n",
    "comp = MultiComparison(df['reliability2'], df['group'])\n",
    "result = comp.allpairtest(scipy.stats.ttest_ind, method='bonf') # 봉페르니\n",
    "print(result[0])\n",
    "\n",
    "#투키의 HSD - Tuckey's Honestly Significant Difference = \"진정으로 유의미한 차이\"\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "hsd = pairwise_tukeyhsd(df['reliability2'], df['group'], alpha=0.05)\n",
    "hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e7abf-506a-4fde-9fce-44a570daead8",
   "metadata": {},
   "source": [
    "## 분석 결과 해석\n",
    ": Pr(>F)== p-value. \n",
    "<hr>\n",
    "\n",
    "### 가설1 : 미디어에 따라 파급력의 차이가 있는가?\n",
    "\n",
    "분산분석: p-value가 0.05보다 작으므로, 집단 간에 통계적으로 유의한 차이가 나타남\n",
    "사후분석: pval의 값이 0.05보다 낮으므로, 방송프로그램과 유튜버 간의 차이가 유의하여 주효과가 나타난다.\n",
    "\n",
    "### 가설2 : 미디어에 따라 파급력을 미치는 크기에 차이가 있는가?\n",
    "\n",
    "분산분석: p-value가 부동소수로 표현 될만큼 낮은 숫자이고, 0.05보다 작으므로 집단 간에 통계적으로 유의한 차이가 나타남\n",
    "사후분석: pval의 값이 0.05보다 낮으므로, 방송프로그램과 연예인 간의 차이가 유의하여 주효과가 나타난다.\n",
    "### 가설3 : 미디어에 따라 글을 작성할 확률에 차이가 있는가?\n",
    "\n",
    "분산분석: p-value가 부동소수로 표현 될만큼 낮은 숫자이고, 0.05보다 작으므로 집단 간에 통계적으로 유의한 차이가 나타남\n",
    "사후분석: pval의 값이 0.05보다 낮으므로, 방송프로그램과 연예인 간의 차이가 유의하여 주효과가 나타난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45545c9d-9873-4049-9bc1-6c6615d11d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
