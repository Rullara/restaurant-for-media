{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c58792-2b2c-4f0d-b50b-4a3652307a49",
   "metadata": {},
   "source": [
    "# 네이버 블로그로 파급력을 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5d96f-b72a-4c52-b196-84dbb6fa99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "# 글에서 해당 키워드 찾기\n",
    "from konlpy.tag import Kkma\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# 트리맵\n",
    "import squarify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fbeefc-d181-49aa-9409-9bfe8d722019",
   "metadata": {},
   "source": [
    "<naverapi 응답 구조>  \n",
    "lastBuildDate : api 요청한 시각  \n",
    "total : 관련 블로그 수  \n",
    "start : 시작  \n",
    "display : 가져온 갯수  \n",
    "items : 블로그  \n",
    "<items 구조>  \n",
    "title : 블로그 제목    \n",
    "link : 블로그 링크  \n",
    "description : 블로그 내용  \n",
    "bloggername : 블로그 이름  \n",
    "bloggerlink : 블로그 메인화면  \n",
    "postdate : 게시날짜  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d291b-d046-48c3-911a-76d2b84e42c7",
   "metadata": {},
   "source": [
    "# 파급력\n",
    "네이버 데이터 : 음식점과 관련성이 높은 블로그글 순으로 200개의 데이터를 가져옵니다.  \n",
    "기준일 : 네이버 데이터 중 제공기관 키워드가 블로그 제목이나 간략한 설명에 들어간 글 중 가장 오래전에 포스트된 날짜  \n",
    "        (관련된 글이 없다면 기준일은 \"2099-12-31 00:00:00\"이 됩니다.)  \n",
    "        \n",
    "## 가게에 대한 신뢰도 : 미디어가 해당 음식점의 영향력에 얼마나 주었나\n",
    "power3 : 해당 미디어의 영향력  \n",
    "reliability2 : 영향력이 얼마나 큰가\n",
    "## 파급력의 신뢰도 : 미디어 파급력에 영향을 받아서 글을 작성할 확률\n",
    "reliability\n",
    "\n",
    "### (후보) 미디어의 파급력 : 미디어가 해당 음식점의 영향력에 얼마나 주었나\n",
    "측정 : 기준일을 기준으로 전과 후에 얼마나 급격하게 포스팅 갯수가 늘어났나  \n",
    "\n",
    "power = (reference_after - reference_before) / 200?  \n",
    "power2 = [resource_count/ {(reference after - resource_count)/ reference before}+ reference before] / reference before    \n",
    "power3 = (기준일 후 게시물 개수 / [(가장 마지막 게시물 날짜- 기준일) / (마지막날짜 - 오래된 날짜) * 100] - 기준일 전 게시물 개수 / [(기준일 - 게시물 중 가장 오래된 날짜) / (마지막날짜 - 오래된 날짜) * 100]\n",
    "\n",
    "\n",
    "(power값이 높을수록 파급력이 좋다. 최댓값 : 200, 최솟값 : -200)  \n",
    "문제점 : 해당 미디어키워드는 고려하지 않았으므로 미디어에 영향을 받아서 간건지 아닌지 알 수 없음\n",
    "### (후보) 미디어의 파급력의 신뢰성 : 측정한 파급력을 얼마나 신뢰해야 할것인가\n",
    "측정 : 기준일을 기점으로 이후 포스팅되는 글 중 해당 미디어를 키워드를 작성한 글의 퍼센트  \n",
    "reliability = resource_count / reference_after * 100%  \n",
    "reliability2 = reference_after/(reference_affter - resource_count) *100%  \n",
    "(reliability값이 높을수록 측정한 파급력을 더 믿을 수 있다.)\n",
    "문제점 : 해당 미디어에 영향을 받았음에도 블로그 제목이나 간략한 내용에 작성하지 않은 사람이 있을 수 있다. 따라서 신뢰성은 매우 낮게 나올 수 밖에 없다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d6e9a-b7e4-4ad6-9c56-7abc62b14093",
   "metadata": {},
   "source": [
    "# 가정\n",
    "\trestaurant\treference_before\treferenceDate\treference_after\tblogTotal\tblogDisplay\tresource_count\n",
    "\t산골농원\t56\t2019-05-24 00:00:00\t144\t5101\t200\t32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af35c44-4120-468c-993c-0a06bf17ee7a",
   "metadata": {},
   "source": [
    "[(32 / {112 / 56}) +56] / 56  \n",
    "(16 + 56) / 56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959bc95-170c-436f-a5cf-5e903b072f8b",
   "metadata": {},
   "source": [
    "가정1 : 이영자님의 영향을 받은 사람은 32명이다.  \n",
    "가정2 : 이영자님의 영향을 받은 사람은 144명이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011c7a8-a2e0-4a1d-bf3f-24d610d50eda",
   "metadata": {},
   "source": [
    "1. 미디어별로 특징별 랜덤으로 5개? 뽑아서 시계열 분석 / 워드 클라우드\n",
    "2. 유형별로 랜덤 5개 knu? 감정 단어 찾기 존맛탱, 맛이-\n",
    "3. 가장 오래된 게시물 날짜 (언급된 날짜)\n",
    "4. 블로그 게시물 총 개수(blog_total)로 히트맵 만들기\n",
    "5. 산점도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b3295-8583-4c5b-9f85-8b069201733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 가져오기\n",
    "naver_total = pd.read_csv(\"./data/naver_blog/total_power.csv\")\n",
    "# 형 변환\n",
    "naver_total[\"oldestDate\"] = pd.to_datetime(naver_total[\"oldestDate\"]).apply(pd.Timestamp)\n",
    "naver_total[\"referenceDate\"] = pd.to_datetime(naver_total[\"referenceDate\"]).apply(pd.Timestamp)\n",
    "naver_total[\"mostRecentDate\"] = pd.to_datetime(naver_total[\"mostRecentDate\"]).apply(pd.Timestamp)\n",
    "# power3열 추가\n",
    "# (기준일 후 게시물 개수 / [(가장 마지막 게시물 날짜- 기준일) / (마지막날짜 - 오래된 날짜) * 100] - 기준일 전 게시물 개수 / [(기준일 - 게시물 중 가장 오래된 날짜) / (마지막날짜 - 오래된 날짜) * 100]\n",
    "# [기준일 후 게시물 개수 / (가장 마지막 게시물 날짜- 기준일) - 기준일 전 게시물 개수 / (기준일 - 게시물 중 가장 오래된 날짜)]* 100 *(마지막날짜 - 오래된 날짜)\n",
    "naver_total[\"power3\"] = ( naver_total[\"reference_after\"] / pd.to_numeric((naver_total[\"mostRecentDate\"] - naver_total[\"referenceDate\"]).dt.days, downcast='integer') - naver_total[\"reference_before\"] / pd.to_numeric((naver_total[\"referenceDate\"] - naver_total[\"oldestDate\"]).dt.days, downcast='integer')) * pd.to_numeric((naver_total[\"mostRecentDate\"] - naver_total[\"oldestDate\"]).dt.days, downcast='integer') / 100\n",
    "# reliability2열 추가\n",
    "naver_total[\"reliability2\"] = naver_total[\"resource_count\"] / (naver_total[\"reference_after\"] - naver_total[\"resource_count\"]) * 100\n",
    "# reliability열 추가\n",
    "naver_total[\"reliability\"] = naver_total[\"resource_count\"] / naver_total[\"reference_after\"] * 100\n",
    "# 결측치 처리 \n",
    "naver_total['power3'].fillna(0, inplace=True)\n",
    "naver_total['reliability2'].fillna(100, inplace=True)\n",
    "naver_total['reliability'].fillna(0, inplace=True)\n",
    "# 그룹열 만들기\n",
    "연예인 = [\"이영자\", \"백종원\", \"성시경\", \"신동엽\", \"최자\", \"비(정지훈)\", \"문세윤\", \"김준현\"]\n",
    "유튜버 = [\"더들리\", \"츄릅켠\"]\n",
    "방송프로그램 = [\"수요미식회\", \"생생정보통\", \"전참시\", \"생활의 달인\", \"6시 내 고향\", \"골목식당\", \"생방송 오늘 저녁\", \"모닝 와이드\", \"맛있는 녀석들\", \"생방송 투데이\"]\n",
    "groups = [연예인, 유튜버, 방송프로그램]\n",
    "groups_names = [\"연예인\", \"유튜버\", \"방송프로그램\"]\n",
    "for i, groups in enumerate(groups):\n",
    "    for media in groups:\n",
    "        naver_total.loc[naver_total[\"resource\"] == media, \"group\"] = groups_names[i]\n",
    "display(naver_total)\n",
    "naver_total.to_csv(\"./data/naver_blog/total_power.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab14d1-d4d6-4767-b0bf-3f3ebfd66f27",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5d4db-da5c-45ad-8980-7a945912ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폰트설정\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"./data/NanumMyeongjo-Bold.ttf\"   #폰트파일의 위치\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name() # rc 함수를 통해, rcParams에 사용되는 폰트의 정식명칭을 알 수 있음\n",
    "print(\"폰트설정 :\", font_name)\n",
    "rc('font', family=font_name)\n",
    "# 데이터 가져오기\n",
    "data = pd.read_csv(\"./data/naver_blog/total_power.csv\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237644f5-113f-4c19-a180-11419d7a3194",
   "metadata": {},
   "source": [
    "## 1. 산점도 그리기 : (resource - power3) (20 - (-? - ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00ea01-fa84-4a39-8483-251022ecd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타일 테마 설정 (5가지: darkgrid, whitegrid, dark, white, ticks)\n",
    "# sns.set_style('white')\n",
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "#이산형 변수의 분포 - 데이터 분산 고려 (중복 X) \n",
    "sns.swarmplot(x=\"resource\",      #x축 변수\n",
    "              y=\"power3\",        #y축 변수\n",
    "              data=data)   #데이터셋 - 데이터프레임\n",
    "\n",
    "# data.plot(kind='scatter', x='resource', y='power3', marker='+',\n",
    "#         cmap='viridis', s=50, alpha=0.3, figsize=(20, 5))\n",
    "plt.title()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b0e18-bc4c-4657-abf8-dd4e9cad08ef",
   "metadata": {},
   "source": [
    "## 2. 나무맵 : 블로그 게시물 개수(200개 아님)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978afd7-ab57-48b2-8d9d-986d9309d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6635e1b-79b3-48cf-b9c3-208a4748bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나무맵 : 전수조사용\n",
    "plt.figure(figsize=(10,5))\n",
    "# 라벨 구하기\n",
    "temp = data.copy()\n",
    "#temp = temp.sort_values(by=\"blogTotal\", ascending = False)\n",
    "temp.loc[temp[\"blogTotal\"] <= 250000,\"restaurant\"] = \"\"\n",
    "squarify.plot(sizes=data[\"blogTotal\"], label = temp[\"restaurant\"], alpha=0.6)\n",
    "plt.axis('off')\n",
    "plt.savefig('./output/treemap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faaabcd-cd05-43a0-a47d-1798f4e4f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나무맵 : 항목별 5개씩\n",
    "rastaurant = pd.read_excel(\"./output/음식점 모음.xlsx\", sheet_name=\"Sheet1\")\n",
    "rastaurant = rastaurant.head(5)\n",
    "temp = pd.DataFrame()\n",
    "연예인 = [\"이영자\", \"백종원\", \"성시경\", \"신동엽\", \"최자\", \"비(정지훈)\", \"문세윤\", \"김준현\"]\n",
    "유튜버 = [\"더들리\", \"츄릅켠\"]\n",
    "방송프로그램 = [\"수요미식회\", \"생생정보통\", \"전참시\", \"생활의 달인\", \"6시 내 고향\", \"골목식당\", \"생방송 오늘 저녁\", \"모닝 와이드\", \"맛있는 녀석들\", \"생방송 투데이\"]\n",
    "names = 연예인 + 유튜버 + 방송프로그램\n",
    "for name in names:\n",
    "    for i in range(len(rastaurant[name])):\n",
    "        mask = (data[\"resource\"] == name) & (data[\"restaurant\"] == rastaurant[name][i])\n",
    "        temp = temp.append(data.loc[mask].head(1))\n",
    "# 라벨 구하기\n",
    "temp.loc[temp[\"blogTotal\"] <= 20000,\"restaurant\"] = \"\"\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10,5))\n",
    "squarify.plot(sizes=temp[\"blogTotal\"], label = temp[\"restaurant\"], alpha=0.6)\n",
    "plt.axis('off')\n",
    "plt.savefig('./output/treemap2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e6cb9-a35e-493d-8b4d-a54039f1fbbc",
   "metadata": {},
   "source": [
    "## 3. 막대 그래프 그리기\n",
    "* file : power3(사람별 - 해당 미디어의 영향력) power3값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?))\n",
    "* (사람별 - 영향력의 크기) reliability2값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?))\n",
    "* (사람별 - 글을 작성할 확률) reliability값을 평균 사람별로(방송별) 막대그래프 (x-20개 y-(-?, ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738fe3b-0273-473e-a2fe-ea4011156729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.groupby(\"resource\").mean()\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf75d24-29de-49e8-843f-0f55da958855",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"사람별 식당 언급 횟수의 평균\")\n",
    "r = df1.resource_count.plot(kind='bar')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e7a81-c49f-4172-b7e1-c8353732ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "x = df1.index\n",
    "y = df1.power3\n",
    "plt.title(\"사람별 파급력(power)과 신뢰도(reliability)의 평균\")\n",
    "my_color = np.where(y>=0, 'skyblue', 'orange')\n",
    "plt.bar(x, y, color=my_color)\n",
    "\n",
    "for i, v in enumerate(x):\n",
    "    if df1.power3[i] > 0:\n",
    "        plt.text(v, y[i], round(df1.reliability[i], 2),       \n",
    "                 fontsize = 9, \n",
    "                 color='black',\n",
    "                 horizontalalignment='center',  \n",
    "                 verticalalignment='bottom') \n",
    "    else :\n",
    "        plt.text(v, y[i], round(df1.reliability[i], 2),       \n",
    "                 fontsize = 9, \n",
    "                 color='black',\n",
    "                 horizontalalignment='center',  \n",
    "                 verticalalignment='top')\n",
    "plt.ylim(-2,19)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23cfbe-6298-4d4f-ab35-bd313dd4734a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. 분산분석을 통하여 3개 이상의 집단 간에 차이가 존재하는지 분석하고자 함\n",
    "\n",
    "가설1 : 미디어에 따라 파급력의 차이가 있는가?  \n",
    "가설2 : 미디어에 따라 파급력을 미치는 크기에 차이가 있는가?  \n",
    "가설3 : 미디어에 따라 글을 작성할 확률에 차이가 있는가?\n",
    "\n",
    "<hr>\n",
    "\n",
    "분산분석(미디어별 - 해당 미디어의 영향력) power값  \n",
    "<p>분산분석(미디어별 - 영향력의 크기) reliability2값</p>\n",
    "<p>분산분석(미디어별 - 글을 작성할 확률) reliability값</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638efc27-aca8-465c-8128-b8d93a3ed656",
   "metadata": {},
   "source": [
    "#### 가설1 : 미디어에 따라 파급력의 차이가 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0a3fc-60fc-403a-935c-ec1e76d62711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "df = data\n",
    "model = ols(\"df['power3'] ~ df['group']\", df).fit()\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4de010-ef55-4150-a8bc-7b84ca54ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집단 간의 차이가 유의할 경우, 어느 집단 간에 차이가 나타나는지 보다 구체적으로 보기 위하여 '사후 분석'을 실시\n",
    "# 여기서는 봉페르니 방식의 교정과 Tukey HSD의 방법으로 사후분석\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "import scipy.stats\n",
    "\n",
    "comp = MultiComparison(df['power3'], df['group'])\n",
    "result = comp.allpairtest(scipy.stats.ttest_ind, method='bonf') # 봉페르니\n",
    "print(result[0])\n",
    "\n",
    "#투키의 HSD - Tuckey's Honestly Significant Difference = \"진정으로 유의미한 차이\"\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "hsd = pairwise_tukeyhsd(df['power3'], df['group'], alpha=0.05)\n",
    "hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2025b9-93da-49cd-8360-3e9067ed198f",
   "metadata": {},
   "source": [
    "#### 가설2 : 미디어에 따라 파급력을 미치는 크기에 차이가 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffebfe5-6d01-4ab2-9a85-24819f263f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"df['reliability'] ~ df['group']\", df).fit()\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e9f22-1d49-48da-bebe-16af6fbb9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집단 간의 차이가 유의할 경우, 어느 집단 간에 차이가 나타나는지 보다 구체적으로 보기 위하여 '사후 분석'을 실시\n",
    "# 여기서는 봉페르니 방식의 교정과 Tukey HSD의 방법으로 사후분석\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "import scipy.stats\n",
    "\n",
    "comp = MultiComparison(df['reliability'], df['group'])\n",
    "result = comp.allpairtest(scipy.stats.ttest_ind, method='bonf') # 봉페르니\n",
    "print(result[0])\n",
    "\n",
    "#투키의 HSD - Tuckey's Honestly Significant Difference = \"진정으로 유의미한 차이\"\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "hsd = pairwise_tukeyhsd(df['reliability'], df['group'], alpha=0.05)\n",
    "hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa15f4b-b7e8-405d-b348-4d42a236c5c5",
   "metadata": {},
   "source": [
    "#### 가설3 : 미디어에 따라 글을 작성할 확률에 차이가 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc427a5a-5f21-4c91-961f-916c5a666f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집단 간의 차이가 유의할 경우, 어느 집단 간에 차이가 나타나는지 보다 구체적으로 보기 위하여 '사후 분석'을 실시\n",
    "# 여기서는 봉페르니 방식의 교정과 Tukey HSD의 방법으로 사후분석\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "import scipy.stats\n",
    "\n",
    "comp = MultiComparison(df['reliability2'], df['group'])\n",
    "result = comp.allpairtest(scipy.stats.ttest_ind, method='bonf') # 봉페르니\n",
    "print(result[0])\n",
    "\n",
    "#투키의 HSD - Tuckey's Honestly Significant Difference = \"진정으로 유의미한 차이\"\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "hsd = pairwise_tukeyhsd(df['reliability2'], df['group'], alpha=0.05)\n",
    "hsd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5a362-bc5c-4a98-8b6d-8becfaba00dd",
   "metadata": {},
   "source": [
    "#### 분석 결과 해석\n",
    ": Pr(>F)== p-value. \n",
    "<hr>  \n",
    "\n",
    "***\n",
    "\n",
    "##### 가설1 : 미디어에 따라 파급력의 차이가 있는가?\n",
    "\n",
    "분산분석: p-value가 0.05보다 작으므로, 집단 간에 통계적으로 유의한 차이가 나타남\n",
    "사후분석: pval의 값이 0.05보다 낮으므로, 방송프로그램과 유튜버 간의 차이가 유의하여 주효과가 나타난다.\n",
    "\n",
    "##### 가설2 : 미디어에 따라 파급력을 미치는 크기에 차이가 있는가?\n",
    "\n",
    "분산분석: p-value가 부동소수로 표현 될만큼 낮은 숫자이고, 0.05보다 작으므로 집단 간에 통계적으로 유의한 차이가 나타남\n",
    "사후분석: pval의 값이 0.05보다 낮으므로, 방송프로그램과 연예인 간의 차이가 유의하여 주효과가 나타난다.\n",
    "##### 가설3 : 미디어에 따라 글을 작성할 확률에 차이가 있는가?\n",
    "\n",
    "분산분석: p-value가 부동소수로 표현 될만큼 낮은 숫자이고, 0.05보다 작으므로 집단 간에 통계적으로 유의한 차이가 나타남\n",
    "사후분석: pval의 값이 0.05보다 낮으므로, 방송프로그램과 연예인 간의 차이가 유의하여 주효과가 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b9b69-da8d-4a80-baa3-36376583f017",
   "metadata": {},
   "source": [
    "### 5. 시계열 / 워드 클라우드(자주 사용하는 단어 찾기) 47- 하니칼국수 - 성시경 / 181-코카모메-츄릅켠 / 270-전참시-몽탄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222a118-e120-4955-b2a2-2cc60280fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [\"하니칼국수_성시경\", \"코카모메_츄릅켠\", \"몽탄_전참시\"]\n",
    "for item in lists:\n",
    "    file = \"./data/naver_blog/rowdata/\" + item + \".csv\"\n",
    "    temp = pd.read_csv(file)\n",
    "    temp.sort_values(by = \"postdate\", ascending=True, inplace=True)\n",
    "    temp.postdate = pd.to_datetime(temp['postdate'])\n",
    "    # 기간 나누기\n",
    "    # temp['period'] = temp['postdate'].dt.to_period(freq='M')  # 년-월\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(10,6))\n",
    "    temp[\"test\"] = 1\n",
    "    plt.hist(temp[\"postdate\"], weights=temp[\"test\"], bins=10, cumulative = True, color=\"orange\")\n",
    "    plt.hist(temp[\"postdate\"], weights=temp[\"test\"], bins=10, cumulative = False, color=\"skyblue\")\n",
    "    plt.title(item + \" 시계열 그래프\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e24a6-ecb2-4084-bd94-1690700303d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [\"하니칼국수_성시경\", \"코카모메_츄릅켠\", \"몽탄_전참시\"]\n",
    "referenceDate = ['2021-05', '2021-08', \"2021-03\"]\n",
    "for i in range(len(filelists)):\n",
    "    file = \"./data/naver_blog/rowdata/\" + filelist[i] + \".csv\"\n",
    "    temp = pd.read_csv(file)\n",
    "    temp.sort_values(by = \"postdate\", ascending=True, inplace=True)\n",
    "    temp.postdate = pd.to_datetime(temp['postdate'])\n",
    "    # 기간 나누기\n",
    "    temp['period'] = temp['postdate'].dt.to_period(freq='M')  # 년-월\n",
    "    # 기간별로 포스트 개수 세기\n",
    "    period_count = temp.groupby(\"period\").count()[[\"postdate\"]]\n",
    "    period_count.rename(columns = {\"postdate\": \"count\"}, inplace=True)\n",
    "    # 누적합 열 추가하기\n",
    "    period_count[\"cum\"] = period_count[[\"count\"]].cumsum()\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(16,8))\n",
    "    # 그래프를 그리기 위한 형변환\n",
    "    period_count.index=period_count.index.to_series().astype(str)\n",
    "    # 기준일 색깔 넣기\n",
    "    my_color = np.where(period_count.index == referenceDate[0], 'skyblue', 'orange')\n",
    "    # 라인그래프 그리기\n",
    "    plt.plot(period_count.index, period_count[\"cum\"], marker='o')\n",
    "    # 기준일 그리기\n",
    "    plt.axvline(referenceDate[i], color='lightgray', linestyle='--', linewidth=2)\n",
    "    plt.text(referenceDate[i], period_count[\"cum\"].max() * 0.95, \"기준선\",       \n",
    "             fontsize = 15, \n",
    "             color='lightgray',\n",
    "             horizontalalignment='center') \n",
    "    # 바그래프 그리기\n",
    "    plt.bar(period_count.index, period_count[\"count\"], color=\"blue\",align='center')\n",
    "    plt.title(filelists[i] + \" 시계열 그래프\")\n",
    "    plt.savefig('./output/' + filelists[i] + ' 시계열 그래프.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a82b6-e792-4172-8822-d6ae4be0889a",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b3b64-5a56-4534-9d4e-84b0a7faecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaverData:\n",
    "    count = -1\n",
    "    power = pd.DataFrame(columns = [\"id\",\"resource\", \"restaurant\", \"oldestDate\", \"reference_before\", \"referenceDate\",\n",
    "                                    \"reference_after\", \"mostRecentDate\", \"blogTotal\", \"blogDisplay\", \"resource_count\"])\n",
    "    power.set_index(['id'], inplace=True)\n",
    "    findData = pd.DataFrame(columns = [\"id\", \"resource\", \"restaurant\", \"data\"])\n",
    "    findData.set_index(['id'], inplace=True)\n",
    "    \n",
    "    def __init__(self, resource, restaurant, display=200, referenceDate=None, data=None):\n",
    "        self.resource = resource\n",
    "        self.restaurant = restaurant\n",
    "        if data is None:\n",
    "            # 네이버 api로 데이터 가져오기\n",
    "            naverData = NaverData.naverBlog(restaurant, display)\n",
    "            self.lastBuildDate = naverData[\"lastBuildDate\"]\n",
    "            self.total = naverData[\"total\"]\n",
    "            self.display = display\n",
    "            self.items = NaverData.cleanIteams(pd.DataFrame(naverData[\"items\"]))\n",
    "        else:\n",
    "            # 로컬 저장소에 있는 데이터 가져오기\n",
    "            tempData = data\n",
    "            self.lastBuildDate = tempData[\"lastBuildDate\"]\n",
    "            self.total = tempData[\"total\"]\n",
    "            self.display = tempData[\"display\"]\n",
    "            self.items = tempData[\"items\"]\n",
    "        self.oldestDate = self.findOldestDate()\n",
    "        self.mostRecentDate = self.findMostRecentDate()\n",
    "        self.referenceData = self.findResource()\n",
    "        self.referenceDate = referenceDate\n",
    "        NaverData.count = NaverData.count + 1\n",
    "        self.id = NaverData.count\n",
    "        self.addPower()\n",
    "        NaverData.findData.loc[self.id] = [resource, restaurant, self]\n",
    "        print(resource, restaurant)\n",
    "    \n",
    "                                               \n",
    "    def __del__(self):\n",
    "        NaverData.power.drop(self.id, inplace=True)\n",
    "        NaverData.findData.drop(self.id, inplace=True)\n",
    "        print(self.id, \"번 데이터를 지웁니다.\")\n",
    "    \n",
    "    # 네이버 ReatAPI\n",
    "    def naverBlog(query, num) :\n",
    "        client_key = 'izGsqP2exeThwwEUVU3x'\n",
    "        client_secret = 'WrwbQ1l6ZI'\n",
    "        encText = urllib.parse.quote_plus(query)\n",
    "        count = [[i,100] for i in range(1, num, 100)]\n",
    "        if num % 100:\n",
    "            count[-1][1] = num % 100 \n",
    "        for i in count:\n",
    "            naver_url = 'https://openapi.naver.com/v1/search/blog.json?query=' + encText + '&display=' + str(i[1]) +'&start=' + str(i[0])\n",
    "            # request 객체에 add하기\n",
    "            request = urllib.request.Request(naver_url)\n",
    "            request.add_header(\"X-Naver-Client-Id\",client_key)\n",
    "            request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            # 응답받은 코드가 정상적인지 확인하기\n",
    "            rescode = response.getcode()\n",
    "            if(rescode == 200):\n",
    "                response_body = response.read()\n",
    "                if i[0] == 1:\n",
    "                    dataList = json.loads(response_body)\n",
    "                else:\n",
    "                    dataList[\"items\"] = dataList[\"items\"] + json.loads(response_body)[\"items\"]\n",
    "            else:\n",
    "                print('오류 코드 : ' + rescode)\n",
    "        return dataList\n",
    "    \n",
    "    def cleanIteams(itemsdf):\n",
    "        \"\"\"\n",
    "        items데이터프라임 -> items데이터프라임\n",
    "         - items데이터프라임 title열과 description열에서 <b></b>&quot; 등 없얘기\n",
    "         - items데이터프레임 postdate 타입을 datetime으로 변경하기\n",
    "        \"\"\"\n",
    "        for i in range(itemsdf.shape[0]):\n",
    "            # title열 데이터 정리하기\n",
    "            title = re.sub(\"<b>|</b>\", \" \", str(itemsdf.loc[i,\"title\"]))\n",
    "            title = re.sub(\"&.{1,5};\", \"\", title)\n",
    "            title = re.sub(\" ( )+\", \"\", title)\n",
    "            itemsdf.loc[i,\"title\"] = title\n",
    "            # description열 데이터 정리하기\n",
    "            description = re.sub(\"<b>|</b>\", \" \", str(itemsdf.loc[i,\"description\"]))\n",
    "            description = re.sub(\"&.{1,5};\", \"\", description)\n",
    "            description = re.sub(\" ( )+\", \"\", description)\n",
    "            itemsdf.loc[i,\"description\"] = description\n",
    "            # postdate열 타입을 datetime로 바꾸기\n",
    "            itemsdf['postdate'] = pd.to_datetime(itemsdf['postdate'])\n",
    "        return itemsdf\n",
    "    \n",
    "    def findResource(self):\n",
    "        \"\"\"\n",
    "        items 데이터프레임 title열과 description열에서 resource단어가 들어간 데이터를 찾아 줍니다.\n",
    "        \"\"\"\n",
    "        kkma = Kkma()\n",
    "        mask = (self.items[\"title\"] + self.items[\"description\"]).map(kkma.nouns).map(lambda x: self.resource in x)\n",
    "        return self.items.loc[mask]\n",
    "    \n",
    "    def findReferenceDate(self):\n",
    "        \"\"\"\n",
    "        찾아온 데이터 중 블로그 제목과 설명에 제공자이름이 들어간 데이터 중 가장 오래된 데이터를 찾습니다.\n",
    "        \"\"\"\n",
    "        if len(self.referenceData) <= 0:\n",
    "            print(\"해당 게시물이 없습니다.\")\n",
    "            return pd.to_datetime('2099-12-31')  \n",
    "        else:\n",
    "            return self.referenceData.sort_values(by='postdate', ascending=True).iloc[0][\"postdate\"]\n",
    "        \n",
    "    def findOldestDate(self):\n",
    "        \"\"\"\n",
    "        찾아온 데이터 중 가장 오래된 데이터를 찾습니다.\n",
    "        \"\"\"\n",
    "        return self.items.sort_values(by='postdate', ascending=True).iloc[0][\"postdate\"]\n",
    "    \n",
    "    def findMostRecentDate(self):\n",
    "        \"\"\"\n",
    "        찾아온 데이터 중 가장 최근 데이터를 찾습니다.\n",
    "        \"\"\"\n",
    "        return self.items.sort_values(by='postdate', ascending=False).iloc[0][\"postdate\"]\n",
    "    \n",
    "    def countBF(self):\n",
    "        \"\"\"\n",
    "        기준일을 기준으로 이전 게시물 갯수와 이후 게시물 갯수를 세줍니다.\n",
    "        반환값 : {'before':X, 'after': X, 'resource_after':X}\n",
    "        \"\"\"\n",
    "        # 기준일을 받지 않으면 게시물 중 가장 오래된 날짜로 지정한다.\n",
    "        if self.referenceDate is None:\n",
    "            self.referenceDate = self.findReferenceDate()\n",
    "        before = len(self.items.loc[self.items['postdate'] < self.referenceDate])\n",
    "        after = len(self.items.loc[self.items['postdate'] >= self.referenceDate])\n",
    "        resource_after = len(self.referenceData.loc[self.referenceData['postdate'] >= self.referenceDate])\n",
    "        return {'before':before, 'after': after, 'resource_after': resource_after}\n",
    "    \n",
    "    def addPower(self):\n",
    "        bf = self.countBF()\n",
    "        NaverData.power.loc[self.id] = [self.resource, self.restaurant, self.oldestDate, bf[\"before\"], self.referenceDate,\n",
    "                                        bf[\"after\"], self.mostRecentDate, self.total, self.display, bf['resource_after']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d93ed-c364-47f6-bfe7-a7e83975b9c2",
   "metadata": {},
   "source": [
    "# (주의! 오래걸립니다..)로컬 저장소에 저장된 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765da71-7d5a-4117-93cb-5226aeacb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rowdata 클래스로 만들기\n",
    "temp = pd.read_csv(\"./data/naver_blog/total_power.csv\")\n",
    "for row in range(len(temp)):\n",
    "    file = \"./data/naver_blog/rowdata/\" + temp.iloc[row][\"restaurant\"] + \"_\" + temp.iloc[row][\"resource\"] + \".csv\"\n",
    "    temp_items = pd.read_csv(file)\n",
    "    data = {\"lastBuildDate\": None, \"total\": temp.iloc[row][\"blogTotal\"], \"display\" : len(temp_items),\n",
    "           \"items\" : temp_items}\n",
    "    try:\n",
    "        NaverData(temp.iloc[row][\"resource\"], temp.iloc[row][\"restaurant\"], data=data)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8729b1-19b2-4122-a838-e18597230139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 정보 가져오기\n",
    "naver_power = pd.read_csv(\"./data/naver_blog/total_power.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9833d-326d-46a7-8276-0d061618ee41",
   "metadata": {},
   "source": [
    "# 음식점 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d15d5-660d-403c-b90c-d3ea81489bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./output/음식점 모음.xlsx\", sheet_name=\"Sheet1\")\n",
    "resource_rastaurantDF = pd.DataFrame(columns = [\"resource\",\"rastaurant\"])\n",
    "# 데이터 변환하기\n",
    "for col in df.columns:\n",
    "    rastaurant = df[col].dropna()\n",
    "    temp = pd.DataFrame({\"rastaurant\": rastaurant, \"resource\" : col})\n",
    "    resource_rastaurantDF = resource_rastaurantDF.append(temp)\n",
    "resource_rastaurantDF.reset_index(inplace=True)\n",
    "resource_rastaurantDF.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b52a2-9d42-4dda-a95e-c5b387d00edc",
   "metadata": {},
   "source": [
    "# 네이버 파급력 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761be8cf-abcf-4d68-9d22-6dd146282d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 멈췄을때를 대비해서 미리미리 저장합니다\n",
    "# 식당데이터를 20개씩 자르기\n",
    "count = list(range(0, len(resource_rastaurantDF), 20)) + [len(resource_rastaurantDF)]\n",
    "for i in range(len(count)-1):\n",
    "    for row in range(count[i], count[i+1]):\n",
    "        # 네이버 api로 데이터 요청하기\n",
    "        tempNaverData = NaverData(resource_rastaurantDF.loc[row, \"resource\"], resource_rastaurantDF.loc[row, \"rastaurant\"])\n",
    "        # 블로그 데이터 저장하기\n",
    "        file = \"./data/naver_blog/rowdata/\" + NaverData.findData.loc[row, \"restaurant\"] + \"_\" + NaverData.findData.loc[row, \"resource\"] + \".csv\"\n",
    "        NaverData.findData.loc[row, \"data\"].items.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce2bf1-b665-492f-8594-e1d993294fa6",
   "metadata": {},
   "source": [
    "# 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6ab97-8901-46d9-9e85-93062d5ca77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(NaverData.power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a73905-8ab8-4046-9ca8-526327f27f3e",
   "metadata": {},
   "source": [
    "# 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a1c03-b31d-4c72-b5f0-156602d41450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파급력 저장하기\n",
    "NaverData.power.to_csv(\"./data/naver_blog/total_power.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ab364-4e39-42a8-be1d-c9ad4bf18da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 items데이터 저장하기\n",
    "for row in range(len(NaverData.findData)):\n",
    "    file = \"./data/naver_blog/rowdata/\" + NaverData.findData.loc[row, \"restaurant\"] + \"_\" + NaverData.findData.loc[row, \"resource\"] + \".csv\"\n",
    "    NaverData.findData.loc[row, \"data\"].items.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6167745-0845-4ac4-9ee4-12de07e26a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 rowdata_resource 데이터 저장하기\n",
    "for row in range(len(NaverData.findData)):\n",
    "    file = \"./data/naver_blog/rowdata_resource/\" + NaverData.findData.loc[row, \"restaurant\"] + \"_\" + NaverData.findData.loc[row, \"resource\"] + \".csv\"\n",
    "    NaverData.findData.loc[row, \"data\"].referenceData.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc7aa8-c687-42ae-9017-333354225783",
   "metadata": {},
   "source": [
    "# 해볼 수 있는일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd1b4a-1db1-4bb8-b8aa-2a2676347d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 메소들 만들기\n",
    "mask = (NaverData.findData[\"resource\"] == \"김준현\") & (NaverData.findData[\"restaurant\"] == \"원조수구레\")\n",
    "NaverData.findData.loc[mask].iloc[0][\"data\"].items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b2d9e-cf8a-43b4-94f1-7fb6fb040f38",
   "metadata": {},
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1b1be-5c3c-4e6b-b5e6-dd5a44d4b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 빼기\n",
    "text = \"민락<동 얼큰칼국수&quot;<b>츄릅켠</b> 님 방송 보고 다녀옴!!!&quot;\"\n",
    "text = re.sub(\"<b>|</b>\", \" \", text)\n",
    "text = re.sub(\"&.{1,5};\", \"\", text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb55b6e-73ea-4f14-9011-ff9c6a5f4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"해운대 원조할매국밥을 찾아가듯이 이 분위기와 쌈밥이 땡길때면 재방문할 의향이 있네요...\"\n",
    "kkma = Kkma() \n",
    "kkma.nouns(sample)\n",
    "# pprint(kkma.morphs(sample))\n",
    "# pprint(kkma.pos(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09044f-d1bc-4756-860b-9c8347b74a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "naverdata1 = NaverData(\"츄릅켠\", \"소문난원조쌈밥\")\n",
    "naverdata2 = NaverData(\"김준현\", \"원조수구레\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e5a10-1acf-428a-95c1-cb419ebc4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([10, 20, 30, 40], [1, 4, 9, 16], c=\"b\",\n",
    "         lw=5, ls=\"--\", marker=\"o\", ms=15, mec=\"g\", mew=5, mfc=\"r\")\n",
    "plt.title(\"스타일 적용 예\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ad344-cfa8-4ad3-95af-5efa3042a4ad",
   "metadata": {},
   "source": [
    "# 문제모음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9274f-4ad6-44ea-923b-32dbd1054eb8",
   "metadata": {},
   "source": [
    "1. 인스턴스가 삭제가 안됩니다.\n",
    "2. 파일 데이터를 불러올때 몇몇의 파일을 읽어오지 못합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3baf27-ef5d-4303-9cb3-a1b5ce704fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폰트설정2\n",
    "sns.set(font=\"Malgun Gothic\", \n",
    "        rc={\"axes.unicode_minus\":False},\n",
    "        style='darkgrid')\n",
    "\n",
    "# 폰트설정3\n",
    "jupyter notebook 내 그래프를 바로 그리기 위한 설정\n",
    "%matplotlib inline\n",
    "# unicode minus를 사용하지 않기 위한 설정 (minus 깨짐현상 방지)\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "# 폰트설정4\n",
    "%matplotlib inline\n",
    "import platform\n",
    "path = './data/THEdog.ttf'\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unkonwn system... sorry~~~~')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
